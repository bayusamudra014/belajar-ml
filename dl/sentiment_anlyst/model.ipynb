{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Book Review Sentiment Model\n",
    "\n",
    "This notebook consists about building sentiment analysis model from Book Review comments. All datasets was scraped from Goodreads on July 2024. Goodreads was choosen because it may have good word and labeling quality. Scraped data format is line json (`.ljson`) which is a single of datum is in one line with format json. The reason I use this format is scalability issue. Scraping method is explained in `scrape.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "To run this notebook, ensure that you have installed below dependencies:\n",
    "1. Tensorflow\n",
    "2. Keras\n",
    "3. Python\n",
    "4. Numpy\n",
    "5. Nltk\n",
    "6. Matplotlib\n",
    "7. Sklearn\n",
    "8. Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 22:46:55.877155: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-21 22:46:55.917267: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-21 22:46:56.590664: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mt\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import nltk\n",
    "\n",
    "import gensim\n",
    "import gensim.downloader\n",
    "\n",
    "from gensim.models import Word2Vec, FastText\n",
    "from datetime import datetime\n",
    "from keras import losses\n",
    "from keras import optimizers\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below results show the version of the library that I used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.1\n",
      "1.26.4\n",
      "3.9.0\n",
      "1.5.0\n",
      "3.8.1\n",
      "4.3.2\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(np.version.full_version)\n",
    "print(mt.__version__)\n",
    "print(sklearn.__version__)\n",
    "print(nltk.__version__)\n",
    "print(gensim.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the constant of this notebook that I used for generating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LANGUAGE = \"english\"\n",
    "WORKER_NUMBER = 16\n",
    "WORD_EPOCH = 20\n",
    "INPUT_SIZE = 300\n",
    "\n",
    "LEARNING_EPOCH = 100\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing\n",
    "\n",
    "The first step of creating sentiment model is text preprocessing. In this step, I remove any unnecessary words, such as 'show more' and punctuations in text. I also do case folding to lowercase in this step. After text has been formatted, I stem every word using `nltk` tools. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BANNED_KEYWORDS = [\n",
    "    \"This entire review has been hidden because of spoilers\"]\n",
    "corpus = []\n",
    "regex = r'[^a-zA-Z0-9\\- \\n\"\\']+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code shows text cleaning process and word tokenize. We save the result at `comments_cleaned.ljson` as cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = list(nltk.corpus.stopwords.words(LANGUAGE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/comments_cleaned.ljson\", \"w\") as fw:\n",
    "    with open(\"datasets/comments.ljson\") as fr:\n",
    "        for line in fr:\n",
    "            data = json.loads(line)\n",
    "\n",
    "            # Skip if the comment contains banned keywords\n",
    "            if any(keyword in data[\"text\"] for keyword in BANNED_KEYWORDS):\n",
    "                continue\n",
    "\n",
    "            result = []\n",
    "            for sentence in nltk.sent_tokenize(data[\"text\"]):\n",
    "                # Case folding\n",
    "                sentence = sentence.lower()\n",
    "\n",
    "                # Stopword removal\n",
    "                sentence = \" \".join([word for word in sentence.split() if word not in stopwords])\n",
    "\n",
    "                # Remove special chars\n",
    "                sentence = re.sub(regex, '', sentence)\n",
    "                sentence = sentence.replace(\"-\", \" \")\n",
    "                sentence = sentence.replace(\"\\n\", \" \")\n",
    "                sentence = sentence.replace(\"\\\"\", \"\")\n",
    "                sentence = re.sub(r'\\bhttp[a-z0-9]+\\b', '', sentence)\n",
    "                sentence = re.sub(r'\\b(img|src)[a-z0-9]*\\b', '', sentence)\n",
    "                sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "\n",
    "                # Remove unnecessary words\n",
    "                sentence = sentence.replace(\"- - - - show more\", \"\")\n",
    "                sentence = sentence.replace(\"show more\", \"\")\n",
    "                sentence = sentence.replace(\"show less\", \"\")\n",
    "\n",
    "                # Remove whitespaces\n",
    "                sentence = sentence.strip()\n",
    "\n",
    "                if len(sentence) < 10:\n",
    "                    continue\n",
    "\n",
    "                result.append(sentence)\n",
    "\n",
    "            # Change rating to integer\n",
    "            data[\"rating\"] = int(data[\"rating\"].split(\" \")[1])\n",
    "            data[\"text\"] = result\n",
    "\n",
    "            if len(data[\"text\"]) == 0:\n",
    "                continue\n",
    "\n",
    "            fw.write(json.dumps(data))\n",
    "            fw.write(\"\\n\")\n",
    "\n",
    "            corpus.extend(data[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code shows corpus enrichment that will used for word2vec datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/corpus.txt\", \"r\") as fr:\n",
    "    for line in fr:\n",
    "        if any(keyword in line for keyword in BANNED_KEYWORDS):\n",
    "            continue\n",
    "\n",
    "        if len(sentence) < 10:\n",
    "            continue\n",
    "\n",
    "        for sentence in nltk.sent_tokenize(line):\n",
    "            # Stopword removal\n",
    "            sentence = \" \".join([word for word in sentence.split() if word not in stopwords])\n",
    "\n",
    "            sentence = sentence.replace(\"\\n\", \" \")\n",
    "            sentence = re.sub(regex, '', line)\n",
    "            sentence = sentence.strip()\n",
    "            sentence = sentence.lower()\n",
    "\n",
    "            sentence = sentence.replace(\"-\", \" \")\n",
    "            sentence = sentence.replace(\"\\\"\", \"\")\n",
    "            sentence = re.sub(r'\\bhttp[a-z0-9]+\\b', '', sentence)\n",
    "            sentence = re.sub(r'\\b(img|src)[a-z0-9]*\\b', '', sentence)\n",
    "            sentence = re.sub(r'\\s{2,}', ' ', sentence)\n",
    "\n",
    "            sentence = sentence.replace(\"- - - - show more\", \"\")\n",
    "            sentence = sentence.replace(\"show more\", \"\")\n",
    "            sentence = sentence.replace(\"show less\", \"\")\n",
    "\n",
    "            if len(sentence) < 10:\n",
    "                continue\n",
    "\n",
    "            if len(sentence) == 0:\n",
    "                continue\n",
    "\n",
    "            corpus.append(sentence)\n",
    "\n",
    "with open(\"datasets/corpus_cleaned.txt\", \"w\") as fw:\n",
    "    fw.write(\"\\n\".join(corpus))\n",
    "\n",
    "# Cleanup\n",
    "corpus = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code shows stemming process on corpus and datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(LANGUAGE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is process of stemming process on corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/corpus_stemmed.txt\", \"w\") as fw:\n",
    "  with open(\"datasets/corpus_cleaned.txt\", \"r\") as fr:\n",
    "      for line in fr:\n",
    "          words = nltk.word_tokenize(line, language=LANGUAGE)\n",
    "          result = \" \".join([stemmer.stem(word) for word in words])\n",
    "\n",
    "          fw.write(result)\n",
    "          fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"datasets/comments_stemmed.ljson\", \"w\") as fw:\n",
    "  with open(\"datasets/comments_cleaned.ljson\", \"r\") as fr:\n",
    "      for line in fr:\n",
    "          data = json.loads(line)\n",
    "          result = []\n",
    "          \n",
    "          for sentence in data[\"text\"]:\n",
    "              words = nltk.word_tokenize(sentence, language=LANGUAGE)\n",
    "              sentence = \" \".join([stemmer.stem(word) for word in words])\n",
    "              result.append(sentence)\n",
    "\n",
    "          fw.write(json.dumps({\n",
    "              \"text\": result,\n",
    "              \"rating\": data[\"rating\"]\n",
    "          }))\n",
    "          fw.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "stemmer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "This section will explain about feature extraction process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceIterator:\n",
    "    \"\"\"This class is used to stream all line over the file.\"\"\"\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "\n",
    "    def __iter__(self):\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                yield line.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec\n",
    "\n",
    "In this section, we will try train Word2Vec model from scratch with text8 dataset and our scraped dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = SentenceIterator(\"datasets/corpus_stemmed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(sentence, workers=WORKER_NUMBER, vector_size=INPUT_SIZE, epochs=WORD_EPOCH)\n",
    "word2vec_model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model checkpoint\n",
    "word2vec_model.save(\"models/corpus_word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the model: 17781\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in the model:\", len(word2vec_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('enjoy', 0.4678633213043213),\n",
       " ('like', 0.46775925159454346),\n",
       " ('and', 0.43738266825675964),\n",
       " ('the', 0.42680367827415466),\n",
       " ('realli', 0.4210198223590851),\n",
       " ('ador', 0.4179684519767761),\n",
       " ('think', 0.4178924262523651),\n",
       " ('know', 0.3722281754016876),\n",
       " ('of', 0.3656740188598633),\n",
       " ('also', 0.3622031509876251)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext\n",
    "\n",
    "In this section, we will try use fasttext model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = SentenceIterator(\"datasets/corpus_stemmed.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model = FastText(sentence, workers=WORKER_NUMBER, vector_size=INPUT_SIZE, epochs=WORD_EPOCH)\n",
    "fasttext_model.get_latest_training_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_model.save(\"models/corpus_fasttext.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in the model: 17781\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of words in the model:\", len(fasttext_model.wv.index_to_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loveh', 0.7908258438110352),\n",
       " ('glove', 0.7520722150802612),\n",
       " ('lovey', 0.7279291152954102),\n",
       " ('loveli', 0.6851240396499634),\n",
       " ('loveabl', 0.6354579925537109),\n",
       " ('loveless', 0.5756585597991943),\n",
       " ('lovecraft', 0.5397000312805176),\n",
       " ('lovecraftian', 0.4944160580635071),\n",
       " ('wove', 0.49380677938461304),\n",
       " ('ador', 0.4839033782482147)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "sentence = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "In this section, we will learn about our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data: 24523\n",
      "Rating distribution: [3279, 4371, 5333, 5808, 5732]\n"
     ]
    }
   ],
   "source": [
    "data_cnt = 0\n",
    "rating = [0,0,0,0,0]\n",
    "\n",
    "with open(\"datasets/comments_stemmed.ljson\", \"r\") as fr:\n",
    "    for line in fr:\n",
    "        data_cnt += 1\n",
    "\n",
    "        data = json.loads(line)\n",
    "        rating[data[\"rating\"] - 1] += 1\n",
    "\n",
    "print(\"Number of data:\", data_cnt)\n",
    "print(\"Rating distribution:\", rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labeling and Data Split\n",
    "\n",
    "In this section, we will label `comments_stemmed` dataset. We will use two scheme of based on rating. Sentiment classification will devide into 3 class, positive (index 0), neutral (index 1), and negative (index 2). The label will be a vector with three element with range value between 0 and 1. This label is a softmax of three class that we defined before.\n",
    "\n",
    "The dataset will be splitted into 3 parts, training with proportion 70% of data, test with proportion 15% of data, and validation with proportion of 15% data.\n",
    "\n",
    "This cells will classify the type of data, whether it is a training data, test data, or validation data randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = np.zeros((data_cnt,), dtype=np.int8)\n",
    "\n",
    "for i in range(0, int(data_cnt * 0.70)):\n",
    "    data_type[i] = 0\n",
    "\n",
    "for i in range(int(data_cnt * 0.70), int(data_cnt * 0.85 + 1)):\n",
    "    data_type[i] = 1\n",
    "\n",
    "for i in range(int(data_cnt * 0.85 + 1), data_cnt):\n",
    "    data_type[i] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, ..., 2, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shuffle data\n",
    "np.random.shuffle(data_type)\n",
    "data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data type distribution: [17166  3679  3678]\n"
     ]
    }
   ],
   "source": [
    "data_type_dist = np.bincount(data_type)\n",
    "\n",
    "print(\"Data type distribution:\", data_type_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_rating_dist = np.zeros((5,), dtype=np.int32)\n",
    "\n",
    "idx = 0\n",
    "with open(\"datasets/comments_stemmed.ljson\", \"r\") as fr:\n",
    "    for line in fr:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        if data_type[idx] == 0:\n",
    "            training_rating_dist[data[\"rating\"] - 1] += 1\n",
    "        \n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training rating distribution: [2313 3056 3779 4048 3970]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training rating distribution:\", training_rating_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme 1\n",
    "\n",
    "In this scheme, we will label data training with this rules:\n",
    "1. Star 5 will be labelled as `[1, 0, 0]`\n",
    "2. Star 4 will be labelled as `[0.55, 0.45, 0]`\n",
    "3. Star 3 will be labelled as `[0, 1, 0]`\n",
    "4. Star 2 will be labelled as `[0, 0.45, 0.55]`\n",
    "5. Star 1 will be labelled as `[0, 0, 1]`\n",
    "\n",
    "For testing, the classification is based on this rules:\n",
    "1. Star 5 and 4 will be labelled as `positive`\n",
    "2. Star 3 will be labelled as `neutral`\n",
    "3. Star 2 and 1 will be labelled as `negative`\n",
    "\n",
    "Those labels are based on the highest element value in resulted vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75010808, 1.32460733, 1.07118285, 1.        , 1.01964736])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calclate data weight\n",
    "data_weight = np.ones((5,), dtype=np.float64) * np.max(training_rating_dist)\n",
    "data_weight = data_weight / training_rating_dist\n",
    "data_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "with open(\"datasets/comments_stemmed.ljson\", \"r\") as fr:\n",
    "    with open(\"datasets/comments_labelled_s1_train.ljson\", \"w\") as ftrain, \\\n",
    "         open(\"datasets/comments_labelled_s1_val.ljson\", \"w\") as fval, \\\n",
    "         open(\"datasets/comments_labelled_s1_test.ljson\", \"w\") as ftest:\n",
    "        for line in fr:\n",
    "            data = json.loads(line)\n",
    "            y = []\n",
    "\n",
    "            if data[\"rating\"] == 1:\n",
    "                y = [0, 0, 1]\n",
    "            elif data[\"rating\"] == 2:\n",
    "                y = [0, 0.45, 0.55]\n",
    "            elif data[\"rating\"] == 3:\n",
    "                y = [0, 1, 0]\n",
    "            elif data[\"rating\"] == 4:\n",
    "                y = [0.55, 0.45, 0]\n",
    "            elif data[\"rating\"] == 5:\n",
    "                y = [1, 0, 0]\n",
    "                        \n",
    "            write_data = {\n",
    "                \"X\": \" \".join(data[\"text\"]),\n",
    "                \"y\": y,\n",
    "                \"w\": data_weight[data[\"rating\"] - 1]\n",
    "            }\n",
    "\n",
    "            write_data = json.dumps(write_data)\n",
    "\n",
    "            if data_type[idx] == 0:\n",
    "                ftrain.write(write_data)\n",
    "                ftrain.write(\"\\n\")\n",
    "            elif data_type[idx] == 1:\n",
    "                fval.write(write_data)\n",
    "                fval.write(\"\\n\")\n",
    "            elif data_type[idx] == 2:\n",
    "                ftest.write(write_data)\n",
    "                ftest.write(\"\\n\")\n",
    "            \n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scheme 2\n",
    "\n",
    "In this scheme, we will label data training with this rules:\n",
    "1. Star 5 will be labelled as `[1, 0, 0]`\n",
    "2. Star 4 will be labelled as `[1, 0, 0]`\n",
    "3. Star 3 will be labelled as `[0, 1, 0]`\n",
    "4. Star 2 will be labelled as `[0, 0, 1]`\n",
    "5. Star 1 will be labelled as `[0, 0, 1]`\n",
    "\n",
    "For testing, the classification is based on this rules:\n",
    "1. Star 5 and 4 will be labelled as `positive`\n",
    "2. Star 3 will be labelled as `neutral`\n",
    "3. Star 2 and 1 will be labelled as `negative`\n",
    "\n",
    "Those labels are based on the highest element value in resulted vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.49338797, 1.49338797, 2.12172532, 1.        , 1.        ])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate data weight\n",
    "high_dist = training_rating_dist[0] + training_rating_dist[1]\n",
    "low_dist = training_rating_dist[3] + training_rating_dist[4]\n",
    "center = training_rating_dist[2]\n",
    "\n",
    "max_dist = max(high_dist, low_dist, center)\n",
    "\n",
    "data_weight = np.ones((5,), dtype=np.float64) * max_dist\n",
    "data_weight = data_weight / np.array([high_dist, high_dist, center, low_dist, low_dist])\n",
    "data_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0\n",
    "with open(\"datasets/comments_stemmed.ljson\", \"r\") as fr:\n",
    "    with open(\"datasets/comments_labelled_s2_train.ljson\", \"w\") as ftrain, \\\n",
    "         open(\"datasets/comments_labelled_s2_val.ljson\", \"w\") as fval, \\\n",
    "         open(\"datasets/comments_labelled_s2_test.ljson\", \"w\") as ftest:\n",
    "        for line in fr:\n",
    "            data = json.loads(line)\n",
    "            y = []\n",
    "\n",
    "            if data[\"rating\"] == 1:\n",
    "                y = [0, 0, 1]\n",
    "            elif data[\"rating\"] == 2:\n",
    "                y = [0, 0, 1]\n",
    "            elif data[\"rating\"] == 3:\n",
    "                y = [0, 1, 0]\n",
    "            elif data[\"rating\"] == 4:\n",
    "                y = [1, 0, 0]\n",
    "            elif data[\"rating\"] == 5:\n",
    "                y = [1, 0, 0]\n",
    "                        \n",
    "            write_data = {\n",
    "                \"X\": \" \".join(data[\"text\"]),\n",
    "                \"y\": y,\n",
    "                \"w\": data_weight[data[\"rating\"] - 1]\n",
    "            }\n",
    "\n",
    "            write_data = json.dumps(write_data)\n",
    "\n",
    "            if data_type[idx] == 0:\n",
    "                ftrain.write(write_data)\n",
    "                ftrain.write(\"\\n\")\n",
    "            elif data_type[idx] == 1:\n",
    "                fval.write(write_data)\n",
    "                fval.write(\"\\n\")\n",
    "            elif data_type[idx] == 2:\n",
    "                ftest.write(write_data)\n",
    "                ftest.write(\"\\n\")\n",
    "            \n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Training\n",
    "\n",
    "In this section, we will explore about training model for sentiment analysis. We will use 3 hyperparameters with each 2 options. The parameters are below:\n",
    "1. Word Model:\n",
    "   We will use `word2vec_model` and `fasttext_model` based on model that we have trained before.\n",
    "2. Classification Model:\n",
    "   We will use two different layer type, that is `GRU` and `Bidirectional GRU`. This model structure will be explained in next cell. \n",
    "3. Dataset Scheme:\n",
    "   We will use two scheme that we have build before, that is `Sheme 1` and `Scheme 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below cell is helper function to do our task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedGenerator:\n",
    "    def __init__(self, filename, word_model):\n",
    "        self.filename = filename\n",
    "        self.word_model = word_model\n",
    "\n",
    "    def generate(self):\n",
    "        with open(self.filename, \"r\") as f:\n",
    "            for line in f:\n",
    "                data = json.loads(line)\n",
    "                X = []\n",
    "\n",
    "                for words in data[\"X\"].split():\n",
    "                    try:\n",
    "                        X.append(self.word_model.wv.get_vector(words))\n",
    "                    except KeyError:\n",
    "                        pass\n",
    "                \n",
    "                if len(X) == 0:\n",
    "                    continue\n",
    "\n",
    "                X = np.array(X)\n",
    "                X = X.reshape((1, X.shape[0], X.shape[1]))\n",
    "                \n",
    "                y = np.array([data[\"y\"]])\n",
    "                w = np.array([data[\"w\"]])\n",
    "                \n",
    "                yield X, y, w\n",
    "\n",
    "def train_model(*, word, classification, train_dataset_filename, validation_dataset_filename, name):\n",
    "    train_gen = EmbedGenerator(train_dataset_filename, word)\n",
    "    validation_gen = EmbedGenerator(validation_dataset_filename, word)\n",
    "\n",
    "    train_ds = tf.data.Dataset.from_generator(train_gen.generate, output_signature=(\n",
    "        tf.TensorSpec(shape=(None, None, INPUT_SIZE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float64),\n",
    "    ))\n",
    "    validation_ds = tf.data.Dataset.from_generator(validation_gen.generate, output_signature=(\n",
    "        tf.TensorSpec(shape=(None, None, INPUT_SIZE), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None, 3), dtype=tf.float32),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.float64),\n",
    "    ))\n",
    "\n",
    "    callback = [\n",
    "      keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        min_delta=0.005,\n",
    "      ),\n",
    "      keras.callbacks.ModelCheckpoint(\n",
    "        filepath=f\"models/checkpoint/{name}_model_checkpoint.keras\",\n",
    "        save_best_only=True,\n",
    "      ),\n",
    "      keras.callbacks.TensorBoard(\n",
    "        log_dir=f\"logs/{name}_{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
    "      ),\n",
    "    ]\n",
    "\n",
    "    if classification == \"layer_1\":\n",
    "      model = keras.models.Sequential([\n",
    "          keras.layers.Input(shape=(None, INPUT_SIZE)),\n",
    "          keras.layers.GRU(128, dropout=0.2),\n",
    "          keras.layers.Dense(128, activation=\"relu\"),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense(128, activation=\"relu\"),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "      )\n",
    "    elif classification == \"layer_2\":\n",
    "      model = keras.models.Sequential([\n",
    "          keras.layers.Input(shape=(None, INPUT_SIZE)),\n",
    "          keras.layers.Bidirectional(\n",
    "            keras.layers.GRU(128, dropout=0.2),\n",
    "          ),\n",
    "          keras.layers.Dense(128, activation=\"relu\"),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense(128, activation=\"relu\"),\n",
    "          keras.layers.Dropout(0.2),\n",
    "          keras.layers.Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "      )\n",
    "    else:\n",
    "      raise ValueError(\"Invalid classification\")\n",
    "    \n",
    "    model.compile(\n",
    "      loss=losses.CategoricalCrossentropy(),\n",
    "      optimizer=optimizers.Adam(),\n",
    "      metrics=[keras.metrics.CategoricalAccuracy()],\n",
    "    )\n",
    "\n",
    "    history = model.fit(\n",
    "      train_ds,\n",
    "      epochs=LEARNING_EPOCH,\n",
    "      callbacks=callback,\n",
    "      validation_data=validation_ds,\n",
    "      batch_size=64,\n",
    "    )\n",
    "\n",
    "    model.save(f\"models/{name}_model.keras\")\n",
    "\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_model = [\n",
    "  (\"word2vec\", Word2Vec.load(\"models/corpus_word2vec.model\")),\n",
    "  (\"fasttext\", FastText.load(\"models/corpus_fasttext.model\")),\n",
    "]\n",
    "classification_scheme = [\n",
    "  (\"layer1\", \"layer_1\"), \n",
    "  (\"layer2\", \"layer_2\")\n",
    "]\n",
    "dataset = [\n",
    "  (\"schema2\",\"datasets/comments_labelled_s2_train.ljson\", \"datasets/comments_labelled_s2_val.ljson\", \"datasets/comments_labelled_s2_test.ljson\"),\n",
    "  (\"schema1\",\"datasets/comments_labelled_s1_train.ljson\", \"datasets/comments_labelled_s1_val.ljson\", \"datasets/comments_labelled_s1_test.ljson\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training schema2_word2vec_layer1 model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 22:51:40.722213: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.753969: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.757760: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.763888: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.768329: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.773154: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.924714: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.927601: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.930976: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:998] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-21 22:51:40.934473: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2099 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  17157/Unknown \u001b[1m947s\u001b[0m 55ms/step - categorical_accuracy: 0.3521 - loss: 1.5797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:07:28.664927: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:07:28.664990: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-21 23:07:28.665012: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n",
      "/home/miawheker/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(typ, value, traceback)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1015s\u001b[0m 59ms/step - categorical_accuracy: 0.3521 - loss: 1.5797 - val_categorical_accuracy: 0.3731 - val_loss: 1.2851\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:08:36.049143: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:08:36.049186: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-21 23:08:36.049194: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-21 23:08:36.049198: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-21 23:08:36.049203: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-21 23:08:36.049211: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17156/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.5091 - loss: 1.2987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:24:37.236854: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-21 23:24:37.236889: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:24:37.236911: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1028s\u001b[0m 60ms/step - categorical_accuracy: 0.5091 - loss: 1.2987 - val_categorical_accuracy: 0.4093 - val_loss: 1.2368\n",
      "Epoch 3/100\n",
      "\u001b[1m    1/17160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44:15\u001b[0m 155ms/step - categorical_accuracy: 0.0000e+00 - loss: 0.9499"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:25:44.328454: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:25:44.328492: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-21 23:25:44.328499: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-21 23:25:44.328504: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-21 23:25:44.328508: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-21 23:25:44.328526: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17158/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - categorical_accuracy: 0.5625 - loss: 1.2338"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:41:48.967157: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:41:48.967201: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-21 23:41:48.967210: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n",
      "2024-07-21 23:41:48.967218: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8660209922884844610\n",
      "2024-07-21 23:41:48.967223: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3885738942126240872\n",
      "2024-07-21 23:41:48.967236: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 7313164164346277876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1033s\u001b[0m 60ms/step - categorical_accuracy: 0.5625 - loss: 1.2338 - val_categorical_accuracy: 0.4011 - val_loss: 1.2244\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:42:57.624496: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:42:57.624526: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Shape/_8]]\n",
      "2024-07-21 23:42:57.624548: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n",
      "2024-07-21 23:42:57.624557: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-21 23:42:57.624566: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17158/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.5813 - loss: 1.2033"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-21 23:59:28.850274: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-21 23:59:28.850316: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-21 23:59:28.850342: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1060s\u001b[0m 62ms/step - categorical_accuracy: 0.5813 - loss: 1.2033 - val_categorical_accuracy: 0.5023 - val_loss: 1.2145\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:00:37.651562: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:00:37.651593: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17157/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.5970 - loss: 1.1786"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:17:10.880765: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:17:10.880797: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-22 00:17:10.880817: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1063s\u001b[0m 62ms/step - categorical_accuracy: 0.5970 - loss: 1.1786 - val_categorical_accuracy: 0.5665 - val_loss: 1.1760\n",
      "Epoch 6/100\n",
      "\u001b[1m    1/17160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m45:27\u001b[0m 159ms/step - categorical_accuracy: 0.0000e+00 - loss: 0.9340"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:18:20.744946: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:18:20.744980: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 00:18:20.744987: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 00:18:20.744992: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-22 00:18:20.744997: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-22 00:18:20.745005: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17158/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.6167 - loss: 1.1461"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:35:01.894998: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:35:01.895030: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-22 00:35:01.895052: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1071s\u001b[0m 62ms/step - categorical_accuracy: 0.6167 - loss: 1.1461 - val_categorical_accuracy: 0.5031 - val_loss: 1.2063\n",
      "Epoch 7/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:36:11.724671: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:36:11.724708: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-07-22 00:36:11.724732: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17158/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - categorical_accuracy: 0.6189 - loss: 1.1781"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:52:55.140862: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:52:55.140909: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-07-22 00:52:55.140932: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8660209922884844610\n",
      "2024-07-22 00:52:55.140943: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1074s\u001b[0m 63ms/step - categorical_accuracy: 0.6189 - loss: 1.1781 - val_categorical_accuracy: 0.4631 - val_loss: 1.2518\n",
      "Epoch 8/100\n",
      "\u001b[1m    1/17160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53:51\u001b[0m 188ms/step - categorical_accuracy: 1.0000 - loss: 0.7350"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 00:54:05.679142: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 00:54:05.679178: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Shape/_8]]\n",
      "2024-07-22 00:54:05.679197: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n",
      "2024-07-22 00:54:05.679204: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 00:54:05.679210: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17159/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.6140 - loss: 1.1707"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:11:08.829751: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:11:08.829789: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-22 01:11:08.829811: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1096s\u001b[0m 64ms/step - categorical_accuracy: 0.6140 - loss: 1.1707 - val_categorical_accuracy: 0.5450 - val_loss: 1.1557\n",
      "Epoch 9/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:12:21.310468: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:12:21.310511: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 01:12:21.310519: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 01:12:21.310523: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-22 01:12:21.310527: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-22 01:12:21.310535: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - categorical_accuracy: 0.6189 - loss: 1.1515"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:29:07.887914: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:29:07.887954: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-22 01:29:07.887983: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1078s\u001b[0m 63ms/step - categorical_accuracy: 0.6189 - loss: 1.1515 - val_categorical_accuracy: 0.5314 - val_loss: 1.2218\n",
      "Epoch 10/100\n",
      "\u001b[1m    1/17160\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m53:06\u001b[0m 186ms/step - categorical_accuracy: 1.0000 - loss: 0.4534"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:30:19.660498: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:30:19.660539: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 01:30:19.660547: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 01:30:19.660551: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-22 01:30:19.660556: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-22 01:30:19.660565: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17157/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.6285 - loss: 1.1371"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:47:25.178003: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:47:25.178043: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-07-22 01:47:25.178071: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8660209922884844610\n",
      "2024-07-22 01:47:25.178081: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1097s\u001b[0m 64ms/step - categorical_accuracy: 0.6285 - loss: 1.1371 - val_categorical_accuracy: 0.4528 - val_loss: 1.2011\n",
      "Epoch 11/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 01:48:36.802025: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 01:48:36.802058: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Shape/_8]]\n",
      "2024-07-22 01:48:36.802082: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n",
      "2024-07-22 01:48:36.802090: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 01:48:36.802099: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17156/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - categorical_accuracy: 0.6250 - loss: 1.1422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:05:54.115916: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:05:54.115953: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2024-07-22 02:05:54.115977: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 8660209922884844610\n",
      "2024-07-22 02:05:54.115991: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1111s\u001b[0m 65ms/step - categorical_accuracy: 0.6250 - loss: 1.1423 - val_categorical_accuracy: 0.4376 - val_loss: 1.2034\n",
      "Epoch 12/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:07:07.949088: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:07:07.949120: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 02:07:07.949128: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 02:07:07.949132: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-22 02:07:07.949137: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-22 02:07:07.949146: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17158/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - categorical_accuracy: 0.6217 - loss: 1.1511"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:24:32.182384: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:24:32.182431: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[StatefulPartitionedCall/Shape/_8]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1118s\u001b[0m 65ms/step - categorical_accuracy: 0.6217 - loss: 1.1511 - val_categorical_accuracy: 0.5978 - val_loss: 1.1755\n",
      "Epoch 13/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:25:45.554320: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:25:45.554364: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 02:25:45.554372: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 02:25:45.554376: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n",
      "2024-07-22 02:25:45.554381: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6641184055736104791\n",
      "2024-07-22 02:25:45.554391: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17157/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - categorical_accuracy: 0.6354 - loss: 1.1683"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:43:30.265949: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:43:30.266006: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n",
      "2024-07-22 02:43:30.266027: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 5211926725495867385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1142s\u001b[0m 67ms/step - categorical_accuracy: 0.6354 - loss: 1.1683 - val_categorical_accuracy: 0.5265 - val_loss: 1.2068\n",
      "\n",
      "Training schema2_word2vec_layer2 model\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 02:44:47.489606: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[Shape/_8]]\n",
      "2024-07-22 02:44:47.489636: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 02:44:47.489654: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 3344087264005042512\n",
      "2024-07-22 02:44:47.489661: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 17457545256597299359\n",
      "2024-07-22 02:44:47.489667: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 15573710527161381431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  17159/Unknown \u001b[1m1827s\u001b[0m 106ms/step - categorical_accuracy: 0.3972 - loss: 1.5481"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:15:14.987604: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 03:15:14.987676: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1925s\u001b[0m 112ms/step - categorical_accuracy: 0.3972 - loss: 1.5481 - val_categorical_accuracy: 0.4196 - val_loss: 1.2683\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:16:52.738016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 03:16:52.738083: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 03:16:52.738096: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12537422810318151163\n",
      "2024-07-22 03:16:52.738105: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6298081848747204061\n",
      "2024-07-22 03:16:52.738115: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11370574172801774674\n",
      "2024-07-22 03:16:52.738132: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2729004245344130420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - categorical_accuracy: 0.5812 - loss: 1.2870"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:47:38.543958: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 03:47:38.544001: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1942s\u001b[0m 113ms/step - categorical_accuracy: 0.5812 - loss: 1.2870 - val_categorical_accuracy: 0.4120 - val_loss: 1.1980\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 03:49:14.579554: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 03:49:14.579603: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 03:49:14.579615: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12537422810318151163\n",
      "2024-07-22 03:49:14.579620: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6298081848747204061\n",
      "2024-07-22 03:49:14.579627: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11370574172801774674\n",
      "2024-07-22 03:49:14.579638: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2729004245344130420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - categorical_accuracy: 0.5978 - loss: 1.1890"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 04:19:47.671987: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 04:19:47.672124: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1926s\u001b[0m 112ms/step - categorical_accuracy: 0.5978 - loss: 1.1890 - val_categorical_accuracy: 0.4289 - val_loss: 1.1999\n",
      "Epoch 4/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 04:21:20.984311: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 04:21:20.984363: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 04:21:20.984375: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12537422810318151163\n",
      "2024-07-22 04:21:20.984383: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6298081848747204061\n",
      "2024-07-22 04:21:20.984394: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11370574172801774674\n",
      "2024-07-22 04:21:20.984408: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2729004245344130420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - categorical_accuracy: 0.5881 - loss: 1.1681"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 04:51:31.816886: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 04:51:31.816943: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1902s\u001b[0m 111ms/step - categorical_accuracy: 0.5881 - loss: 1.1681 - val_categorical_accuracy: 0.4011 - val_loss: 1.2211\n",
      "Epoch 5/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 04:53:02.902045: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 04:53:02.902090: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_6]]\n",
      "2024-07-22 04:53:02.902099: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 12537422810318151163\n",
      "2024-07-22 04:53:02.902105: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 6298081848747204061\n",
      "2024-07-22 04:53:02.902112: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 11370574172801774674\n",
      "2024-07-22 04:53:02.902122: I tensorflow/core/framework/local_rendezvous.cc:422] Local rendezvous recv item cancelled. Key hash: 2729004245344130420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - categorical_accuracy: 0.5950 - loss: 1.1547"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:22:51.886373: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 05:22:51.886431: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17160/17160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1878s\u001b[0m 109ms/step - categorical_accuracy: 0.5950 - loss: 1.1547 - val_categorical_accuracy: 0.4098 - val_loss: 1.2671\n",
      "Epoch 6/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-22 05:24:21.374966: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-07-22 05:24:21.375016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "\t [[IteratorGetNext/_2]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11128/17160\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m10:23\u001b[0m 103ms/step - categorical_accuracy: 0.6140 - loss: 1.1437"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m cname, classification \u001b[38;5;129;01min\u001b[39;00m classification_scheme:\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassification\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataset_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_dataset_filename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mwname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mcname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m()\n",
      "Cell \u001b[0;32mIn[34], line 93\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(word, classification, train_dataset_filename, validation_dataset_filename, name)\u001b[0m\n\u001b[1;32m     85\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classification\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m     88\u001b[0m   loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mCategoricalCrossentropy(),\n\u001b[1;32m     89\u001b[0m   optimizer\u001b[38;5;241m=\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(),\n\u001b[1;32m     90\u001b[0m   metrics\u001b[38;5;241m=\u001b[39m[keras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy()],\n\u001b[1;32m     91\u001b[0m )\n\u001b[0;32m---> 93\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEARNING_EPOCH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m  \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:314\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator\u001b[38;5;241m.\u001b[39menumerate_epoch():\n\u001b[1;32m    313\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 314\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pythonify_logs(logs)\n\u001b[1;32m    316\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1500\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1498\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1500\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1501\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1503\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1504\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1505\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1506\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1507\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1508\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1509\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1510\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1514\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1515\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/tensorflow/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for dname, train, validation, test in dataset:\n",
    "    for wname, wmodel in word_model:\n",
    "        for cname, classification in classification_scheme:\n",
    "            print(f\"Training {dname}_{wname}_{cname} model\")\n",
    "            train_model(\n",
    "                word=wmodel,\n",
    "                classification=classification,\n",
    "                train_dataset_filename=train,\n",
    "                validation_dataset_filename=validation,\n",
    "                name=f\"{dname}_{wname}_{cname}\",\n",
    "            )\n",
    "            print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
